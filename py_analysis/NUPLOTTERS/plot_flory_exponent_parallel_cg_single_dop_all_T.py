#!/home/satyend/.conda/envs/data_analysis/bin/python

import numpy as np 
import re 
import matplotlib
matplotlib.use('Agg')
import matplotlib.cm as cm
import matplotlib.pyplot as plt 
import pandas as pd
import os
import time 
import sys 
sys.path.insert(0, '/scratch/gpfs/satyend/MC_POLYMER/polymer_lattice/lattice_md/Explicit_Solvation/py_analysis')
import aux 
import multiprocessing 
import itertools
from sklearn.linear_model import LinearRegression 
from sklearn.linear_model import HuberRegressor

os.system("taskset -p 0xfffff %d" % os.getpid())
os.environ['MKL_NUM_THREADS'] = '1'
os.environ['NUMEXPR_NUM_THREADS'] = '1'
os.environ['OMP_NUM_THREADS'] = '1'

sys.stdout.flush() 

'''
This code will take in a trajectory file generated by my MonteCarlo engine and 
gives you the flory exponent
'''
''' 
shebang for cluster: #!/usr/licensed/anaconda3/2020.7/bin/python
shebang for homemachine: #!/usr/bin/env python3
'''


import argparse 
parser = argparse.ArgumentParser(description="Read a trajectory file and obtain the flory exponent from that file.")
parser.add_argument('-dop', metavar='DOP', dest='dop', type=int, action='store', help='enter a degree of polymerization.')
parser.add_argument('-s', metavar='S', type=int, dest='s', action='store', help='start parsing after this move number (not index or line number in file).', default=100)
parser.add_argument('--coords', dest='c', metavar='coords.txt', action='store', type=str, help='Name of energy dump file to parse information.', default='coords.txt')
parser.add_argument('-nproc', metavar='N', type=int, dest='nproc', action='store', help='Request these many proccesses.')
parser.add_argument('-d1', dest='d1', metavar='d1', action='store', type=int, help='Starting index.')
parser.add_argument('-d2', dest='d2', metavar='d2', action='store', type=int, help='End index.')
args = parser.parse_args() 

divnorm = matplotlib.colors.SymLogNorm (0.005, vmin=-0.1, vmax=0.1)


def get_starting_ind (T, model, num, dumpfile):
    filename = str(T) + "/FORM1/" + model + "/" + dumpfile + "_" + str(num) + ".mc"
    df = pd.read_csv(filename, sep=' \| ', names=["energy", "mm_tot", "ms_tot", "time_step"], engine='python', skiprows=0)
    L = len(df["energy"])

    return int(df["time_step"].values[L-2000])


# def get_avg_amounts (U, T, num, dop, coords_file, starting_index, d1, d2):
# 	x = list (np.arange (d1, d2+1))
# 	y = []
#	starting_index = get_starting_ind (U, T, num, dop, "energydump")
#	for delta in x:
#		y.append ( aux.single_sim_flory_exp (U, T, num, dop, coords_file, starting_index, delta) )

#	return (np.array (x), np.array (y))


def single_sim_flory_exp ( T, model, num, coords_file, starting_index, delta ):
	filename = str(T)+"/FORM1/"+coords_file+"_"+str(num)+".mc"
	edge     = aux.edge_length (dop)
	master_dict  = aux.get_pdict( filename, starting_index, dop, edge, edge, edge) 
	offset_list  = []

	for key in master_dict:
		coord_arr    = aux.unfuck_polymer ( master_dict[key][0], edge, edge, edge ) 
		delta_coords = coord_arr [0:dop-delta] - coord_arr [delta:]
		offset = list(np.linalg.norm ( delta_coords, axis=1 ) **2 )
		offset_list.extend(offset)

	return np.mean (offset_list)


def get_flory (T, model, num, coords_file, d1, d2):
    x = list (np.arange(d1, d2+1))
    y = []
    starting_index = get_starting_ind (T, model, num, "energydump")
    for delta in x:
        y.append ( single_sim_flory_exp (U, T, num, dop, coords_file, starting_index, delta ) )

    x = np.asarray (np.log(x)).reshape((-1,1))
    y = np.asarray (np.log(y))
    # print (y, flush=True)
    model = HuberRegressor()
    model.fit(x, y)
    r2 = model.score (x, y)
    return (model.coef_, r2)


if __name__ == "__main__":

    start = time.time() 
    ##################################
    T_list    = [0.01, 0.02, 0.05, 0.1, 0.3, 0.5, 1.0, 2.5, 5.0, 10.0, 17.5, 25.0, 50.0, 100.0]
    nmod_list = []
    DB_DICT = {}
    DB_DICT["T"]  = []
    DB_DICT["d1"] = []
    DB_DICT["d2"] = []
    DB_DICT["nu_mean"] = []
    DB_DICT["nu_err" ] = []
    DB_DICT["nu_r2"  ] = []
    flory_dict    = {}
    r2_dict       = {} 
    ntraj_dict = {}
    dop            = args.dop
    coords_files   = args.c
    starting_index = args.s
    nproc          = args.nproc
    
    fig = plt.figure( figsize=(8,6) )
    ax  = plt.axes() 
    ax.tick_params(direction='in', bottom=True, top=True, left=True, right=True, which='both')
    ax.tick_params(axis='x', labelsize=16)
    ax.tick_params(axis='y', labelsize=16)
    i = 0

    for T in T_list:
        nmod_list.append ( np.max ( aux.dir2nmodel( os.listdir (str(T) + "/FORM1/.") ) ) )

    # instantiating pool
    pool1 = multiprocessing.Pool ( processes=nproc )
    pool_list = [pool1]

    # find the max model numbers 
    results = pool_list[0].starmap ( get_flory, zip(T_list, nmod_list, itertools.repeat(1), itertools.repeat(coords_files), itertools.repeat (args.d1), itertools.repeat(args.d2) ) )
    
    DB_DICT["T"].extend (T_list)
    DB_DICT["nu_mean"].extend (results[0])
    DB_DICT["r2"].extend (results[1])
    DB_DICT["d1"].extend ([args.d1]*len(T_list))
    DB_DICT["d2"].extend ([args.d2]*len(T_list))
    df = pd.DataFrame.from_dict (DB_DICT)
    df.to_csv ("FLORY-FORM1-"+str(args.d1)+"-"+str(args.d2)+".mc", sep='|', index=False)

    '''
    for T in T_list:
        print ( "Inside T = " + str(T) + "...", flush=True )
        
        
        # get num_list for each temperature
        master_temp_list = []
        master_num_list  = []
        flory_mean = []
        flory_err  = []
        flory_r2   = []
        flory_dict.clear()
        r2_dict.clear()
        ntraj_dict.clear()
        for T in temperatures:
            # print ("T is " + str(T), flush=True)
            num_list = list(np.unique ( aux.dir2nsim (os.listdir (str(T) + "/FORM1" ) ) ) )
            master_num_list.extend ( num_list )
            master_temp_list.extend ( [T]*len( num_list ) )
            ntraj_dict[T] = len ( num_list )
            flory_dict[T] = []
            r2_dict   [T] = []

        # start multiprocessing... keeping in mind that each node only has 96 cores
        # start splitting up master_num_list and master_temp_list
        idx_range = len (master_num_list)//nproc + 1

        for uidx in range(idx_range):
            if uidx == idx_range-1:
                results = pool_list[ 0 ] .starmap ( get_flory, zip( itertools.repeat(U), master_temp_list[uidx*nproc:], master_num_list[uidx*nproc:], itertools.repeat(dop), itertools.repeat(coords_files), itertools.repeat(starting_index), itertools.repeat(args.d1), itertools.repeat(args.d2) ) )
            else:
                results = pool_list[ 0 ] .starmap ( get_flory, zip( itertools.repeat(U), master_temp_list[uidx*nproc:(uidx+1)*nproc], master_num_list[uidx*nproc:(uidx+1)*nproc], itertools.repeat(dop), itertools.repeat(coords_files), itertools.repeat(starting_index), itertools.repeat(args.d1), itertools.repeat(args.d2) ) )

            print ("Pool has been closed. This pool has {} threads.".format (len(results) ), flush=True )
            for k in range(len(master_temp_list[uidx*nproc:(uidx+1)*nproc])):
                flory_dict[master_temp_list[uidx*nproc+k]].append ( results[k][0] )
                r2_dict   [master_temp_list[uidx*nproc+k]].append ( results[k][1] )


        for T in np.unique (master_temp_list):
            flory_mean.append ( np.mean ( flory_dict[T] ) )
            flory_err.append  ( np.std  ( flory_dict[T] ) / np.sqrt ( ntraj_dict[T] ) )
            flory_r2.append   ( np.mean ( r2_dict[T] ) )

        DB_DICT["U"].extend       ([U]*len(flory_mean))
        DB_DICT["T"].extend       (temperatures)
        DB_DICT["d1"].extend      ([args.d1]*len(flory_mean))
        DB_DICT["d2"].extend      ([args.d2]*len(flory_mean))
        DB_DICT["nu_mean"].extend (flory_mean)
        DB_DICT["nu_err"].extend  (flory_err)
        DB_DICT["nu_r2"].extend   (flory_r2)

    pool1.close()
    pool1.join()
    
    i=0
    df = pd.DataFrame.from_dict (DB_DICT)
    df.to_csv ("FLORY-EXCL-"+str(args.d1)+"-"+str(args.d2)+".mc", sep='|', index=False)
    
    stop = time.time()
    
    print ("Run time for N = " + str(args.dop) + " is {:.2f} seconds.".format(stop-start), flush=True)
    '''
